{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline:\n",
    "\n",
    "This is a MLE baseline for the gender reinflection task. The baseline models $argmax$ $p(trg_w | src_w, trg_g)$, where $trg_w$ is the target word, $src_w$ is the source word and $trg_g$ is the target gender. This baseline makes sense because the source sentence and the target sentence always have the same length and perfect alignment. So to implement this model, we will simply implement the following: $$p(trg_w | src_w, trg_g) = \\dfrac{count(trg_w, src_w, trg_g)}{count(src_w, trg_g)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import operator\n",
    "import sacrebleu\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample:\n",
    "    \"\"\"Simple object to encapsulate each data example\"\"\"\n",
    "    def __init__(self, src, trg, \n",
    "                 src_g, trg_g):    \n",
    "        self.src = src\n",
    "        self.trg = trg\n",
    "        self.src_g = src_g\n",
    "        self.trg_g = trg_g\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.to_json_str())\n",
    "    \n",
    "    def to_json_str(self):\n",
    "        return json.dumps(self.to_dict(), indent=2, ensure_ascii=False)\n",
    "    \n",
    "    def to_dict(self):\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataset:\n",
    "    \"\"\"Encapsulates the raw examples in InputExample objects\"\"\"\n",
    "    def __init__(self, data_dir):\n",
    "        self.train_examples = self.get_train_examples(data_dir)\n",
    "        self.dev_examples = self.get_dev_examples(data_dir)\n",
    "        self.test_examples = self.get_dev_examples(data_dir)\n",
    "        \n",
    "    def create_examples(self, src_path, trg_path):\n",
    "        \n",
    "        src_txt = self.get_txt_examples(src_path)\n",
    "        src_gender_labels = self.get_labels(src_path + '.label')\n",
    "        trg_txt = self.get_txt_examples(trg_path)\n",
    "        trg_gender_labels = self.get_labels(trg_path + '.label')\n",
    "        \n",
    "        examples = []\n",
    "        \n",
    "        for i in range(len(src_txt)):\n",
    "            src = src_txt[i].strip()\n",
    "            trg = trg_txt[i].strip()\n",
    "            src_g = src_gender_labels[i].strip()\n",
    "            trg_g = trg_gender_labels[i].strip()\n",
    "            input_example = InputExample(src, trg, src_g, trg_g)\n",
    "            examples.append(input_example)\n",
    "        \n",
    "        return examples\n",
    "    \n",
    "    def get_labels(self, data_dir):\n",
    "        with open(data_dir) as f:\n",
    "            return f.readlines()\n",
    "        \n",
    "    def get_txt_examples(self, data_dir):\n",
    "        with open(data_dir, encoding='utf8') as f:\n",
    "            return f.readlines()\n",
    "    \n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Reads the train examples of the dataset\"\"\"\n",
    "        return self.create_examples(os.path.join(data_dir, 'D-set-train.arin'), \n",
    "                                    os.path.join(data_dir, 'D-set-train.ar.M'))\n",
    "    \n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Reads the dev examples of the dataset\"\"\"\n",
    "        return self.create_examples(os.path.join(data_dir, 'D-set-dev.arin'), \n",
    "                                    os.path.join(data_dir, 'D-set-dev.ar.M'))\n",
    "    \n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"Reads the test examples of the dataset\"\"\"\n",
    "        return self.create_examples(os.path.join(data_dir, 'D-set-test.arin'), \n",
    "                                    os.path.join(data_dir, 'D-set-test.ar.M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RawDataset('/home/ba63/gender-bias/christine_2019/Arabic-parallel-gender-corpus/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8566"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples = dataset.train_examples\n",
    "len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"src\": \"عمل تقتضيه العلاقات العامة و كنت قلقة من ردة فعلها حول ميمي و التي عادة ما تتكبر على أي امرأة أخرى\",\n",
       "  \"trg\": \"عمل تقتضيه العلاقات العامة و كنت قلقا من ردة فعلها حول ميمي و التي عادة ما تتكبر على أي امرأة أخرى\",\n",
       "  \"src_g\": \"F\",\n",
       "  \"trg_g\": \"M\"\n",
       "}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[8557]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngrams(sentence, ngrams=2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "     - sentence (str): a list of words\n",
    "     - ngrams (int): 2 for bigrams, 3 for trigrams, etc..\n",
    "    Returns:\n",
    "     - ngrams list of the sentece\n",
    "    \"\"\"\n",
    "    return [sentence[i - (ngrams - 1): i + 1] for i in range(ngrams - 1, len(sentence))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLE:\n",
    "    \"\"\"MLE to model P(t_w | s_w, t_g)\"\"\"\n",
    "    \n",
    "    def __init__(self, examples):\n",
    "        self.model = self.build_model(examples)\n",
    "        \n",
    "    def build_model(self, examples):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - examples (list): list of InputExample objects\n",
    "        Returns:\n",
    "            - model (dict): \n",
    "        \"\"\"\n",
    "        \n",
    "        model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.context_counts = dict()\n",
    "        for i, ex in enumerate(examples):\n",
    "\n",
    "            src = ex.src\n",
    "            trg = ex.trg\n",
    "            src_g = ex.src_g\n",
    "            trg_g = ex.trg_g\n",
    "            src = src.split(' ')\n",
    "            trg = trg.split(' ')\n",
    "            \n",
    "            for i, trg_w in enumerate(trg):\n",
    "                # counts of (t_w, s_w, t_g)\n",
    "                model[(src[i], trg_g)][trg_w] += 1\n",
    "                # counts of (s_w, t_g)\n",
    "                self.context_counts[(src[i], trg_g)] = 1 +  self.context_counts.get((src[i], trg_g), 0)\n",
    "            \n",
    "        # turning the counts into probs\n",
    "        for sw, trg_g in model:\n",
    "            for trg_w in model[(sw, trg_g)]:\n",
    "                model[(sw, trg_g)][trg_w] = float(model[(sw, trg_g)][trg_w]) / self.context_counts[(sw, trg_g)] \n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def __getitem__(self, sw_tg):\n",
    "        if sw_tg in self.model:\n",
    "            return dict(self.model[sw_tg])\n",
    "        else:\n",
    "            return {'<unk>': 0.0}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15059\n"
     ]
    }
   ],
   "source": [
    "mle = MLE(train_examples)\n",
    "print(len(mle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(mle, src, trg_g):\n",
    "    \"\"\"Generates a sentence based on the mle model. \n",
    "    At each time step, the model will pick the word with maximum prob\"\"\"\n",
    "    src = src.split(' ')\n",
    "    target = []\n",
    "    for sw in src:\n",
    "        candidates = mle[(sw, trg_g)]\n",
    "#         print(candidates)\n",
    "        argmax = max(candidates.items(), key=operator.itemgetter(1))[0]\n",
    "        target.append(argmax)\n",
    "\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interesting Examples from the D-set-train.arin (input) dataset: <br/>\n",
    "`generate_sentence(mle, 'أصبحت نظيفة .', 'M')`<br/>\n",
    "`gold: أصبحت نظيفا .`\n",
    "\n",
    "`generate_sentence(mle, 'عمل تقتضيه العلاقات العامة و كنت قلقة من ردة فعلها حول ميمي و التي عادة ما تتكبر على أي امرأة أخرى', 'M')`<br/>\n",
    "`gold: عمل تقتضيه العلاقات العامة و كنت قلقا من ردة فعلها حول ميمي و التي عادة ما تتكبر على أي امرأة أخرى`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'أصبحت': 1.0}\n",
      "{'نظيف': 0.25, 'نظيفة': 0.5, 'نظيفا': 0.25}\n",
      "{'.': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'أصبحت نظيفة .'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(mle, 'أصبحت نظيفة .', 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'عمل': 1.0}\n",
      "{'تقتضيه': 1.0}\n",
      "{'العلاقات': 1.0}\n",
      "{'العامة': 1.0}\n",
      "{'و': 1.0}\n",
      "{'كنت': 1.0}\n",
      "{'قلق': 0.75, 'قلقا': 0.25}\n",
      "{'من': 1.0}\n",
      "{'ردة': 1.0}\n",
      "{'فعلها': 1.0}\n",
      "{'حول': 1.0}\n",
      "{'ميمي': 1.0}\n",
      "{'و': 1.0}\n",
      "{'التي': 0.75, 'الذي': 0.25}\n",
      "{'عادة': 1.0}\n",
      "{'ما': 1.0}\n",
      "{'تتكبر': 1.0}\n",
      "{'على': 1.0}\n",
      "{'أي': 1.0}\n",
      "{'رجل': 0.5555555555555556, 'رجلا': 0.2777777777777778, 'امرأة': 0.16666666666666666}\n",
      "{'أخرى': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'عمل تقتضيه العلاقات العامة و كنت قلق من ردة فعلها حول ميمي و التي عادة ما تتكبر على أي رجل أخرى'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(mle, 'عمل تقتضيه العلاقات العامة و كنت قلقة من ردة فعلها حول ميمي و التي عادة ما تتكبر على أي امرأة أخرى', 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1224"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_examples = dataset.dev_examples\n",
    "len(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"src\": \"يقولون بأنني أملك جمال كنز وطني .\",\n",
       "  \"trg\": \"يقولون بأنني أملك جمال كنز وطني .\",\n",
       "  \"src_g\": \"B\",\n",
       "  \"trg_g\": \"B\"\n",
       "}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_examples[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'يقولون': 1.0}\n",
      "{'بأنني': 1.0}\n",
      "{'أملك': 1.0}\n",
      "{'<unk>': 0.0}\n",
      "{'<unk>': 0.0}\n",
      "{'<unk>': 0.0}\n",
      "{'.': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'يقولون بأنني أملك <unk> <unk> <unk> .'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(mle, dev_examples[10].src, dev_examples[10].trg_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_preds(model, examples, output_dir):\n",
    "    refs = []\n",
    "    preds = []\n",
    "    a = open(output_dir, 'w', encoding='utf8')\n",
    "    for ex in examples:\n",
    "        src = ex.src\n",
    "        trg = ex.trg\n",
    "        src_g = ex.src_g\n",
    "        trg_g = ex.trg_g\n",
    "        \n",
    "        pred = generate_sentence(model, src, trg_g)\n",
    "        a.write(pred)\n",
    "        a.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(mle, train_examples, \\\n",
    "'/home/ba63/gender-bias/christine_2019/Arabic-parallel-gender-corpus/edits_annotations/baseline.train.M.outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(mle, dev_examples, \\\n",
    "'/home/ba63/gender-bias/christine_2019/Arabic-parallel-gender-corpus/edits_annotations/baseline.dev.M.outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1224"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_examples = dataset.test_examples\n",
    "len(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(mle, test_examples, \\\n",
    "'/home/ba63/gender-bias/christine_2019/Arabic-parallel-gender-corpus/edits_annotations/baseline.test.M.outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
